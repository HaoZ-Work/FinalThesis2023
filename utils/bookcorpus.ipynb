{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset bookcorpus (/home/dtdysh/.cache/huggingface/datasets/bookcorpus/plain_text/1.0.0/eddee3cae1cc263a431aa98207d4d27fd8a73b0a9742f692af0e6c65afa4d75f)\n",
      "100%|██████████| 1/1 [00:17<00:00, 17.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train'])\n",
      "740042.28\n",
      "{'text': 'usually , he would be tearing around the living room , playing with his toys .'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "bookcorpus_dataset = load_dataset('bookcorpus')\n",
    "\n",
    "# 查看数据集中包含的split。常见的split有'train', 'test', 'validation'。\n",
    "print(bookcorpus_dataset.keys())\n",
    "\n",
    "# 查看某个split（如'train'）的数据大小\n",
    "print(len(bookcorpus_dataset['train'])*0.01)\n",
    "\n",
    "# 查看数据集的一些样例\n",
    "print(bookcorpus_dataset['train'][0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T14:10:40.985917500Z",
     "start_time": "2023-06-27T14:10:20.668767800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74004.228\n"
     ]
    }
   ],
   "source": [
    "print(len(bookcorpus_dataset['train'])*0.001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T07:36:46.371921900Z",
     "start_time": "2023-06-28T07:36:46.301927900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing train and test data: 100%|██████████| 202500/202500 [00:17<00:00, 11743.83it/s]\n",
      "Writing dev data: 100%|██████████| 22500/22500 [00:01<00:00, 11743.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_to_csqa(example):\n",
    "    # 获取当前text的最后一个词作为正确答案\n",
    "    last_word = example[\"text\"].split()[-1]\n",
    "\n",
    "    # 构建CSQA格式的数据\n",
    "    csqa_example = {\n",
    "        \"id\": str(uuid.uuid4()),  # 使用uuid4生成随机id\n",
    "        \"question\": {\n",
    "            \"choices\": [{\"label\": \"A\", \"text\": last_word}],  # 只有一个选项，即正确答案\n",
    "            \"stem\": example[\"text\"]  # 原文本作为问题描述\n",
    "        },\n",
    "        \"answerKey\": \"A\"  # 因为只有一个选项，所以答案键始终为A\n",
    "    }\n",
    "\n",
    "    return csqa_example\n",
    "\n",
    "dataset_size = 225000\n",
    "train_size = int(dataset_size * 0.8)  # 80% for training\n",
    "test_size = int(dataset_size * 0.1)  # 10% for testing\n",
    "dev_size = dataset_size - train_size - test_size  # 10% for dev\n",
    "\n",
    "# IDs for training set\n",
    "ids_train = []\n",
    "\n",
    "# Write the training data and testing data\n",
    "with open('../data/bookcorpus/train_rand_split.jsonl', 'w') as f:\n",
    "    for i in tqdm(range(train_size + test_size), desc=\"Writing train and test data\"):\n",
    "        csqa_example = convert_to_csqa(bookcorpus_dataset['train'][i])\n",
    "        if i < train_size:  # Only save the id for real training set\n",
    "            ids_train.append(csqa_example[\"id\"])  # Save ID\n",
    "        f.write(json.dumps(csqa_example) + '\\n')  # Write each example in JSON format\n",
    "\n",
    "# Write the dev data\n",
    "with open('../data/bookcorpus/dev_rand_split.jsonl', 'w') as f:\n",
    "    for i in tqdm(range(train_size + test_size, dataset_size), desc=\"Writing dev data\"):\n",
    "        csqa_example = convert_to_csqa(bookcorpus_dataset['train'][i])\n",
    "        f.write(json.dumps(csqa_example) + '\\n')  # Write each example in JSON format\n",
    "\n",
    "# Write IDs for training set\n",
    "with open('../data/bookcorpus/inhouse_split_qids.txt', 'w') as f:\n",
    "    for id in ids_train:\n",
    "        f.write(f\"{id}\\n\")\n",
    "\n",
    "print(\"done\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T09:50:00.724918Z",
     "start_time": "2023-06-28T09:49:41.481809100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Then create or copy a test_rand_split_not_answers.jsonl as test set. But we will only use inhouse test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T10:45:44.673028600Z",
     "start_time": "2023-06-28T10:45:44.669028600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
